{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# IF CODE CRASHES THEN RE-RUN THE CODE #\n",
    "# POSSIBLE REASONS: INTERNET SLOW DOWN #\n",
    "# WHILE EXECUTING THE CODE             #\n",
    "########################################\n",
    "\n",
    "\n",
    "# Packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Disable Chrome Browser Notification\n",
    "option = Options()\n",
    "option.add_argument(\"--disable-infobars\")\n",
    "option.add_argument(\"start-maximized\")\n",
    "option.add_argument(\"--disable-extensions\")\n",
    "option.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 1 \n",
    "})\n",
    "\n",
    "\n",
    "# Create driver session\n",
    "driver = webdriver.Chrome(options=option,executable_path = '/Users/gourabsinha/Desktop/Data Science/Packages/chromedriver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Login to Instagram\n",
    "\"\"\"\n",
    "Answer: Here I have visited the site and then I found the input fields where I will need to \n",
    "input the user name and the password and then I have passed the inputs with the\n",
    "send key function. Once these two fields are filled with correct username and password\n",
    "I just clicked on the login button which I have found using button tag.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "driver.get('https://instagram.com/')\n",
    "\n",
    "# Credentials\n",
    "username = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"username\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"password\")))\n",
    "username.clear()\n",
    "password.clear()\n",
    "username.send_keys(\"sample\")\n",
    "password.send_keys(\"sample\")\n",
    "\n",
    "btn = driver.find_elements_by_tag_name(\"button\")\n",
    "btn[1].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodtalkindia\n",
      "dilsefoodie\n",
      "foodnetwork\n",
      "foodgod\n",
      "foodandwine\n",
      "buzzfeedfood\n",
      "food\n",
      "fitwaffle\n",
      "foodinrupiah\n",
      "food52\n",
      "love_food\n",
      "foodinsider\n",
      "gmo_gus\n",
      "indozonefood\n",
      "newfoodsuk\n",
      "foodsofjane\n",
      "wholefoods\n",
      "alphafoodie\n",
      "foodwellmcr\n",
      "feelgoodfoodie\n",
      "foodintheair\n",
      "fitnessfoodhelp\n",
      "hazelzakariya\n",
      "yustrength\n",
      "trfhomemade.id\n",
      "foodstirs\n",
      "aferfind\n",
      "cchannel_food_id\n",
      "ajfotoworld\n",
      "cy_eats\n",
      "besar_food\n",
      "foodnetworkkitchen\n",
      "choppedandfood\n",
      "shonda1020\n",
      "mrs_foodee\n",
      "worldfoodprogramme\n",
      "jasonsfoodhall\n",
      "irishtimesfood\n",
      "yourfoodlab\n",
      "foodtank\n",
      "foodzmything\n",
      "coolfoodmadrid\n",
      "foodrepublic\n",
      "foodtrb\n",
      "albaik\n",
      "thefoodbabe\n",
      "outstandingfoods\n",
      "favorfood\n",
      "lonelyplanetfood\n",
      "jacobs_food_diaries\n",
      "myfoodandfamily\n"
     ]
    }
   ],
   "source": [
    "#Q2. Search\n",
    "\"\"\"\n",
    "Answer: Just to make sure I am on correct site so I again visited Instagram.com\n",
    "Once that is done, now we logged into account in the previous question script so\n",
    "we don't need to do it again. I tried to find the search input field with\n",
    "xpath and then I clear the input fields so that we are not putting\n",
    "any unwanted value. After that I put only required value and then waited for \n",
    "the list to appear. Once the list appear I have picked all the options\n",
    "that were showing and then I segregated the user_handles with hashtags and location \n",
    "by explore and store to a list. Which I am printing at the last. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "driver.get('https://instagram.com/')\n",
    "search_input =    driver.find_element_by_xpath(\"//input[@placeholder='Search']\")\n",
    "search_input.clear()\n",
    "search_input.send_keys(\"food\")\n",
    "user_ids = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='fuqBx']//a\")))\n",
    "\n",
    "\n",
    "# Store user_handles\n",
    "store_user_ids = []\n",
    "for user_id in user_ids:\n",
    "    html_content = user_id.get_attribute('outerHTML')\n",
    "    data = BeautifulSoup(html_content,'html.parser').a['href'].split('/')[1]\n",
    "    if data!='explore':\n",
    "        store_user_ids.append(data)\n",
    "\n",
    "# Print handles\n",
    "for handle in store_user_ids:\n",
    "    print(handle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3-4.1 User handle\n",
    "\"\"\"\n",
    "Answer: The process for input in the search input field is same. The differnce\n",
    "here is that we need to go to that particular handle so once the list appeared \n",
    "I have picked the one which is matching with input and visited the the profile.\n",
    "\"\"\"\n",
    "\n",
    "driver.get('https://instagram.com')\n",
    "search_input = driver.find_element_by_xpath(\"//input[@placeholder='Search']\")\n",
    "search_input.clear()\n",
    "search_input.send_keys(\"So Delhi\")\n",
    "\n",
    "user_id = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"fuqBx\"]//a')))\n",
    "user_id.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Following\n"
     ]
    }
   ],
   "source": [
    "#Q4.2 Follow\n",
    "\"\"\"\n",
    "Answer:  Now we are on the user_handle page now we just need to follow if not already followed.\n",
    "In order to do that, first of all I tried to find the button and I have found the button by\n",
    "xpath and then I clicked over it if not follwing. If already following then\n",
    "I am printing that one.\n",
    "\"\"\"\n",
    "\n",
    "follow_button = driver.find_element_by_xpath(\"//span[@class = 'vBF20 _1OSdk']/button\")\n",
    "\n",
    "# Follow\n",
    "type_button = BeautifulSoup(follow_button.get_attribute('outerHTML'),'html.parser')\n",
    "if type_button.text == 'Following':\n",
    "    print('Already Following')\n",
    "else:\n",
    "    follow_button.click()\n",
    "    print(\"Now Following\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Unfollowed\n"
     ]
    }
   ],
   "source": [
    "#Q4.3 Unfollow\n",
    "\"\"\"\n",
    "Answer: As we are on the same page so we just need to unfollow. I am doing\n",
    "that by clicking on the unfollow button then I am confirming it by clicking\n",
    "unfollow on the alter window.\n",
    "\"\"\"\n",
    "\n",
    "type_button = BeautifulSoup(follow_button.get_attribute('outerHTML'),'html.parser')\n",
    "if type_button.text!='Follow':\n",
    "    follow_button.click()\n",
    "    time.sleep(2) \n",
    "    unfollow = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//button[@class=\"aOOlW -Cab_   \"]')))\n",
    "    unfollow.click()\n",
    "    print(\"Now Unfollowed\")\n",
    "else:\n",
    "    print('Already Unfollowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liked 30 recent posts\n",
      "Unliked 30 recent posts\n"
     ]
    }
   ],
   "source": [
    "#Q5.1 - Q5.2 Like and Unlike Top 30 Posts\n",
    "\"\"\"\n",
    "Answer: Here I have created one function which is handling like and dislike of posts.\n",
    "The function takes one argument i.e what we want to do and based on that it likes or unlikes\n",
    "the post and it does for top 30 posts. If any post is already liked or unliked then it prints\n",
    "that the following action which we want to do has already been done. Process of searching\n",
    "the handle is same. \n",
    "\"\"\"\n",
    "def like_unlike_post(choose):\n",
    "    driver.get('https://instagram.com')\n",
    "    search_input = driver.find_element_by_xpath(\"//input[@placeholder='Search']\")\n",
    "    search_input.clear()\n",
    "    search_input.send_keys(\"dilsefoodie\")\n",
    "    time.sleep(3)\n",
    "    user_id = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"fuqBx\"]//a')))\n",
    "    user_id.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    post = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='v1Nh3 kIKUG  _bz0w']\")))\n",
    "    post.click()\n",
    "    time.sleep(3)\n",
    "    i = 1\n",
    "    while True:\n",
    "        like_button = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//article/div/section/span/button[@class='wpO6b ']\")))\n",
    "        type_button = BeautifulSoup(like_button.get_attribute('innerHTML'),'html.parser').find('svg').get('aria-label')\n",
    "        \n",
    "        if type_button.strip().lower()==choose.strip().lower():\n",
    "            like_button.click()\n",
    "        else:\n",
    "            print('Already {}d'.format(choose))\n",
    "        time.sleep(2)\n",
    "        next_post = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div/a[@class=' _65Bje  coreSpriteRightPaginationArrow']\")))\n",
    "        next_post.click()\n",
    "        i+=1\n",
    "        time.sleep(3)\n",
    "        if i==31:\n",
    "            print(\"{}d 30 recent posts\".format(choose.title()))\n",
    "            driver.execute_script(\"arguments[0].click();\", driver.find_element_by_xpath(\"//div[@class='_2dDPU CkGkG']/div/button[@class='wpO6b ']\"))\n",
    "            break\n",
    "        \n",
    "        \n",
    "\n",
    "# Like 30 Posts of dilsefoodie\n",
    "like_unlike_post(\"like\")\n",
    "# Unlike  30 Posts of dilsefoodie\n",
    "like_unlike_post(\"unlike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni.hao.restro', 'sahilnana', 'abhinandan_ashwath', 'debojani_bora', 'rosticeria.pachupollo', 'chefpratyush', 'idyllic_philodox', 'mekhalalaud', 'sunanda_bhandari_', 'sonisam_name_is_enough', 'ashraful6079', 'aditi993', 'bhaktimandke', 'irfan_shamsi.67', 'sha.ikhsaloni', 'megha.kiara', 'eat.lazeez', 'garg_mahek', 'my_passion_food_stories', 'vaibhav._.dhand', 'ashanagdev29', 'workaholicmommy', 'rupal2323', 'hemameghnani', 'aashuu_9099', 'arsachins', 'anvi_718', 'nishu_love1595', 'shahealamchaudhary_', 'ta.ni9876', 'urval.patel', 'lucky_143_k', 'shivangipoddar_', '2461_mayank', 'sheermal_', 'h.a.z.z.e.r', 'mazharalam386', 'z27_barmanagement', 'the_anandraj', 'utastechamparan', 'mandyagh', 'gambhirbhumika', 'zainab_khaled_22', 'm.m.s.s.ff', 'gangster__yadav_1', 'foodonplanetearth', 'anu_n_aurna', 'mandhabhargavireddy', 'yulin.esm', 'frenzy_cook', 'bhatan24', 'shruti.s.35912', 'butterdabeli', 'sam_hitha_08', 'meju_iml', 'cluburbantyro', 'mou_89', 'nethra.ravindran', 'sonal1363', 'priyank_9_7_', 'niladri.banerjee', 'majid_maqbool08', 'charuupaliwalxx', 'hundal__pb__65', 'sindhu_nift', 'chandnikhannahds', 'shweta.kapil.kohli67', 'mahak.malik', 'r_a_m98', 'clickalmost', 'nidhimundralohia', 'teatonic08', 'friends_who_always_hungry', 'themindofaa', '__v_key___xx_', 'niyazahmed34', 'santasydivinas', 'swag_bebe_nishtha', 'vishalkhairmode', 'withlovefromanushya', 'urmi_trivedi_', 'acsan_studio', 'monika.tak.1253', 'leena.das.94214', 'anuradha.hora', 'nasreen.afzal.779', 'samperes90', 'amazinguuuu19', 'regnamaras', 'adithyapn', 'gayatrighole', 'gokulan_nt', 'gandotraashwani', 'sidhsaini7ms', 'itsmekaptan', 'earthworks_studios', 'chandankumarpatna02', 'khatwanideepa01', 'nirajnavadiyaworld', 'hiral_juthani09', 'rimoluiz', 'sunnychona', 'moni.ca7974', 'giftonclick', 'jsamyak2003', '_theindianmalvaniguy_', 'rana_foodie', 'sonalarora26', 'marathiculinarytales', 'thedesibuffet', 'tbtulip', 'skailash21', 'krupasanghavi01', 'nivi_b737', 'highhjack', 'brownnancylynn', 'shivu.arora', 'the_humming_moon_1436', 'niludhamani', 'babrytagore', '_sweetyjamshed_', 'roni81042', 'basicallykshitij', 'prathap3131', 'pragyasachdevaa', '_iamchandan_6862_wala', '_krishna_gurjar_ji', 'haryanvi_desi_boys_', 'amaresh.seal', 'editerboy9', 'sandeeep.sharmaa007', 'akhisanju', 'saikp1', 'ranikolar', 'aroramohan619', 'deeraj_t', 'rajinder.sehgal.96', 'sarojomkar', 'replytolav', 'choudhary_arjun_rathour_2002', 'samaira45khan', 'simmidesai68', 'anjalisach', 'dailymotivations00', 'atomicbomb.fr', 'manavimdhooli', 'shoaib1827', 's_n_a_ps_h_o_t', 'dasrothin', 'nits.1997', 'himanshu__hop', 'vermarajat452', 'radhikamahalanobis', 'raaji_1411', 'sahil26', 'spicy.suraj', 'sardar__arpita', 'nirmal7007___', 'prateek_2219', 'aatira_zamir', 'thedevourcouple', 'bhukkad_ghummkkad', 'kale_sukesh', 'pooja8100', 'desiadda98', 'bhartichauhan25', 'life.thyme', 'nitinrokade2022', 'anchal7835', 'vegadmired', 'anilsmenon123', 'sairamsweetsindia', 'khushsharmaa', 'nidhikillawala', 'eatsfoodie_itsdelhi', 'puneet5159', 'vaijanathmahantashettar', 'being_akki_z1', 'xx__.aafi.__xx', 'ankitachauhan07', 'lufiamandalulu643', 'tuto963', 'shoan.shinde', 'thalichef', 'deep1995dumka', 'agarwal_shally', '_pooja_chawla_', 'veer_to', '_.truestriver', 'daniyal14102019', 'pratyushkesh.1', '____shit_happens____', 'quarantine_guy_', 'thali.chef', 'kd_eventz', 'quarantine__food', 'next.level09', 'mr.touheed', 'sh.vp.1329', 'ushasanthanneethu', 'amit_pingolia', 'drmonekenstein', 'bahuran123', 'food_n_love', 'sanampatil4', 'mukeshray2395', 'krisheek', 'yummie_diaries_', 'indorifood09', 'waishu_17', 'indiesfoodiess', 'gourav_shriwaliya', 'sociobuy', 'the_alcoholicbiker', 'i_nihung', 'hspamr._', 'khandelane9', 'najibdarbar', 'cookingsbyandy', 'the_barnacle_chronicles', '_sahiilll._64', 'ayu_j965', 'callradz', 'subhashini_devarajan', 'monika.swain1305', 'sai_sudha_valisekka', 'dhallparul97', 'kungfu_foodiepanda', 'anwesha_p11', 'swadhin_kumar.naik', 'foodiemoody1', 'bhoomikagahlot2002', 'ghimire5614', 'akashmalviya418', 'khaaa_moksh', 'travel_eat93', 'chef_tadake', 'sucritak', 'simratbindra', 'tubrin_durai', 'san.ketadabar', 'tastyfiesta_', 'rathour8944', 'misslittlehits', '_the_crackling_mustard_', 'kula.naidu', 'kitchenrvs', 'recookedrecipes', 'miss___singh___', 'raj_bhanushali67', 'tomatotomaahto', 'vigneshvenugopal', 'devilinshortpants_', 'vanitayadav39', '_lysaqistinaaa', 'wandering_the_earth_24', 'shaju7', 'fuzail_banazeer246', 'rout_abhi1997', 'ghosh_rohon', 't_u_r_k_a_r', 'mr_kp__13', 'kashishdharod', 'ankit__singh_official_', 'kartik2.sharma', 'food.mahal', 'its__yar', 'nauman_shaikhhhh', 'aashishpatole', 'joshvillafane', 'cook_with_shalinii', 'ziva_creative_corner', 'nehasporty111990', 'sumanmondal5001', 'safina.perween', 'befikra995', '_incredible_india_91', 'jkjoyce44', '_utsavsingh09', 'viku4545', 'kikishomekitchen', 'leenas83', 'imirealestate', 'mohmaadshanawaz', 'priyankas_food_hub', 'chef_mohammadshaid_jinabade', 'megharath', '_harshaa_k', 'kya_yaar_surin_', 'shafeeqkhan2504', 'buonappetito.mne', 'saswatighosh96', 'utopiic_travel_club', 'miarocher99', 'darkbrowncafe15', 'musings.of.a.flauner', 'thethinelephant', 'prativabhalla', 'vaibhavthakur7717', 'mital_111', 'mudassir_mohammad', 'saumya.atri', 'coalcasrl', 'shivangi_mallick', 'foodl.ve', 'pillllii', 'snapeatpostrepeat', 'hunger_factory', 'angry_beard_boi', 'cute_munda4321', 'souravpandey243', 'bharatsharmaaa', 'nicc_pune', 'dil.preet.kaur', 'rosme1998', 'vikasbathediya7492', 'the_feel_cafe', 'ganeshyadav5457', 'khushbuhshethgmailcom', 'sizzlinslices', 'teju___7', 'bells_gifts', 'abhishek_shah_220', 'pavinstaa', 'jarlandcompa', 'theultimate.food', 'rebeccapanikker', 'the_hfq_recipes', 'deepgagan568', 'divy.a7770', 'siddhidesai_2025', 'hasithagolla', 'arj1568', 'ippitizer', 'itzzzaaaaaaa', 'aasiabegum60', 'dubai_mallufoodie', 'sundar8205', 'shashanksingh8281', 'omkar3790', 'sri.n.kumar', 'mersal.velu.980', 'adityamaggo', 'shyamalmodi', 'thefoodlifeofdindin', 'resuh17', 'rise0099', 'r.gupta2307', 'harshbhagat659', 'ramandeepkaur15', 'krishaaaa.p', 'bexreview', 'ariyanbepary0178', 'isithacaarealplace', 'kaintfood', '_maged_maher_', 'adibafatima_', 'hibasidiqqui', '_lovepreet_saini_379', '_vishakha_07', 'gandhevenkatesh2718', 'parvezmeer007', 'khyatisunita', 'krithi.p.543', '____neon____girl_____', 'dial.food', 'nirali_reshamiya', 'swaadbuds', 'shakthi_vc', 'a_food_love_story', 'black3007_', 'awinningdish', 'grandmum.in.the.kitchen', 'vk0104', 'surbhii_rathore5826', '_jai_sahu_', 'princealmas44', 'popeyethesailor199', 'chef__ap', 'esselselina080', 'mayamtamdesign', 'anoyraj', 'thevittlecravers', 'prave5h', 'pranavvarma08', 'ppriyadarsh', 'anjalinishad6', 'phoenixc__law', '_old_monk_98', 'prosafeliving', 'luna_smrita', 'food.sector', 'simiran_1999', 'anisha.shah.754365', 'sharmakhanakh25', 'aravindhtittu', 'jeewanrajendersingh', 'goodfoodgoodmood_v', 'amateurbakingbyyush', 'mr.shah_dj', 'ssatishsoham', 'msmedisetty', 'fhinexpo', 'moms.secret.chef', 'essence.of.food', 'trolls_familly', 'iameshwarr', 'kadbanoo.kitchen', 'ram_dhatarwal55', 'rajnikant.shukla.7965', 'foodoholic_diaries', 'earthmoon10000', 'kashyap_sarvaliya', 'vivek_chawriya_', 'libranbyheart', 'nemarampat', 'mehahuaaz', 'aj_ajmat_khan67', 'studio.square.design.co', 'jitindutt', 'sadly.sexy', 'digitalkitchenprojects', 'angopalak', 'oyefoodieoye', '__anuuuuu__', 'krazzymoments', 'amritmaansahnewali', 'literallyayna', 'chefandreamura', 'prakriti_29_', 'carlos_88s', 'kmukherjee13041989', 'f.majazi', 'hemantbanchari', 'therambhatla', 'jaredsmth', 'drinkshunya', 'food.with.love.and.butter', 'harsh_vardhan4484', 'mo_nu7168', 'rohasdaud', 'pojo1906', 'harshddes', 'niyamaorganic', 'aslam_khan_7151', 'yashmaihar', 'nusrat__parveen', 'kriti_k21', 'sanyam_kundlia', 'devyaninautiyal', 'sa.ifkhan585', 'ree_hana__', 'sameeresmati48820', 'faiqa.hasan_bukhari', 'kirti.mangla', 'mr_prince_charlie_', 'kolkata_on_my_plate', '103studios', 'lily.151501', 'sudo_unzip_pandora.s_heart', '_zohan_ali_07', 'mr__rx__psycho', 'santipaolino', 'simonenko_sergii', 'itsrivardhan', 'mr.satyashahofficial', 'keshavboola', 'hr_51_wala_', 'zeynab_2279', 'bdivesh', 'verma.vandana', 'ru.755_6', '_manthan_0216', 'citymandi_business', '_fork_it_up', 'ayahromo9', 'leenajore', 'nancy._2145', 'krisschef2019', '_models20', 'saralagesrange', 'raina_deepika', 'biplavkumar007', 'chetfakir', 'vignesh_sg1', '_jerin_mathew', 'foodbank___', 'officiall_g_o_u_r_a_v_', 'soniadevnani', 'pavit_hajettyd', 'only_vegeterian', 'rulan_', 'siyuuuuu____', 'vinodh.kumar.52', 'swatisoni1653', 'rah_ma100', 'dream_spicy2', 'prachikale291', 'i_am_islamuddin', 'raizadanandan']\n",
      "['yoursteju', 'makreloaded', '_namit_13', 'chefpratyush', 'only__retouch', 'akshayalagh', 'mayank._.sharma09', 'riya_tyagi077', 'mekhalalaud', 'the_eyes_of_angel', 'd_tiktok_queenn', 'ritikachaudhary21', 'kanganananana', 'mehta_aashima23', 'paras_mittal172', 'jiggu___99', 'prince.alam.75098', 'anksm22', 'tdeepk7', 'aniisshapadhariia', 'she_be_slayin', 'mylens_world', '3akshar', '_hrithik_77', 'ashraful6079', 'aditi993', 'divyansh.saluja.108', 'may_bxoxo93', 'tripti_crazy', 'kartik.ahuja21', 'vijay_kumar1572', 'barnwalsamiksha', 'salmaabdulhaleem', 'miss_counsel', 'nikhalas___', 'amour_rihu', 'innovativefilmstudio', 'jaismin_singh', 'deepikaajaiswal', 'shaivya_aggarwal', 'vaishali.kesharigmai', 'shwetaman_19', 'r.singh7314', '_vrinda22', 'pbfriend', 'chetanraj.26', 'kirtiworlikar', 'sonia.gogna.wingat', 'aashish_raghav111', 'akanshaa_28', '06neha.nc', 'pictures_speak004', 'khanzeba1702', 'sanajunejaa', 'vaishali13singh', 'shibuagnihotri', 'summertimemad', 'herejosef', 'sahilasuren', 'shubham.agnihotri.73307', 'jyotitalwar22', 'khushiiigupttaa', 'aakash_150_sharma', 'nikunj_3621', 'kapmehta', 'sukhmanikochar_', 'saachimathu', 'saumya.dhawan', 'workaholicmommy', 'vanshmahajan_', 'srabani598', 'dreamit_liveit_repeatit', 'tarun__arora__', 'tript.kaur19', 'mk.nidheesh', 'impactingmentality', 'dhwani2101', 'prarthna_gupta', '_riya___sharma', 'keshkumar_mandavi', 'yogeshpruthi50', 'iammoneshrao', 'lustforlifebyshivs', 'jarjiz444', 'anushakintali', 'alok__13', 'chalbaenikalre', '__rounakk', 'ambikapathania', 'rishab90663', 'kiranjit_photography', 'shraddha.sonar.18', 'kushal_25.5', 'mdgulfam198223', 'sheermal_', 'gul_gautam', 'msn_photoshoot', 'dt_neha13', 'yash_chandna_', 'ayush_tyagi20', 'utastechamparan', 'iam_sagittarius_girl', 'reshma_sharma123', 'kraizada88', 'anil_tkd24', 'thegreesmonkey', 'ammar06siddiquee11', 'bhavnajanmejay', 'dreamssbyhand', 'makeupbydrishu', 'sachin_chef_5336', 'photographer.aman15', 'hasnain_r_', 'anil__patel____', 'komalkapoor_kk', 'yuvi_kapoor.0', 'thakurr_____', 'foody_odiya', 'kumar345678890', 'himanshu25.11', 'pranav_bhandari_625', 'alex.raj9000', 'doglover19982020', 'borntosmileofficial', 'fatizahur', 'sugandha_27', 'foodtalkdubai_official', 'behlsanjay9', 'mntanushree', 'komalifestyle', 'naman_devil', 'anku.jasspeakswriteen', 'dheerajsolanki12', 'eatpeanutbutterandliftheavy', 'hemantkumawat_hk', 'purvasha', 'aanchalaroraa', 'andreilacandidoperes', 'sahiba5178', 'ashishfurtado', 'alpham_official', 'aflatoonn__', 'suk_ruti', 'wreck.ing_7', 'maithilee_joshi_', 'anton_ananyev', 't_wink', 'shokri1852', 'anubhaa_arora', 'shiv.am237', 'irfanqureshiumair', 'faridabadsocial', 'saja.d7731', '_writing_for_healing_', 'livfreely9', 'blissful_sira', 'its.sarthaksharma', 'davinderxo', 'samrddhiii', 'charuupaliwalxx', '___.tvoya_jealous.__', '_sheena.bhatia_', '__mr___sharma__', 'sandybalofficial', '22.walia', 'siddharthsain', 'aprvshrm', 'alina24500', 'sanskrity_jain', 'jasnoorsethi2020', 'binnysuneja', 'rajput_ps18', 'gulshan_rana2321', 'marshmello9._', 'sun_bey_gaurav', 'leza926', 'harshabhagwani321', 'vaibhavdhand1', 'reality_motivational_quotes', 'meghamegha817', 'yoyoarun1995', 'rewildress', 'parthism_18', 'aditi.wahal', 'devendercharkhiya', 'ankit.khilwani', 'diya_sindhwani', '_unicornyaa_', 'rishu.23', 'ajay2877yadav', 'chetna_6', 'supriyapriyadarshini_', 'priyekhana', 'gaganbatra', 'prolooks_12', 'vaani.aryan12', 'vyasalpas', 'ankitpatel8296', 'friends_who_always_hungry', 'khushwinderkalra', 'khushbu.shah25', 'hydrogen_07', 'januarysejanuaryse', 'kumar9373', 'themasalastory', 'rahulk30055', 'pramod_gurjar__', 'paixaossouza', 'malik_madeed', 'jonmanimahanta', 'dc_vella', 'lakshay_shokhanda', 'shivanee_jat_18', 'iamchelsi_', 'yashwant7991', 'arushi_1201', 'kisha_choksi', 'kirtiyadav1808', 'lilia.mayer6', 'veronica_talwar13', 'kaur_sucheta', 'neerusbombay', 'akthar165', 'yashsharma_bdesi', 'nishtha_sadh', 'habib.in.9733', 'v1kkram', '_caramelcupcakes_', 'dodokajou', 'jainsahaab.007', 'shaanmalik9', 'popwhims', 'foodie_boyrk', 'ankit.aqualite', 'hemangi_anand', 'evadetheordinary', 'anush_goel', 'aditya_raghu.04', 'vedikaa__', '_every_whereist', '__silent_beast__', 'thatsoruchi', 'hansa_pandey11', 'anishr.r.96', 'amitjain08081970', 'the_painted_lens', '_momos_momma_', 'art_to_feel_free', 'amarnath2522', 'samikshaseekary', 'g.c.297', 'galib.khan2010', 'siddharth_9781', 'shyam_view23', 'foodieagraaaaa', 'diaries_of_punjaban', 'arnishjain', 'kusumavijaykumar', 'crazy.prerna.10', 'rahulreddy_51847', 'pankajpuri_', '__palvit_prayan', 'divyanswho', 'bhaskar_karn', 'ayushi.rai29', 'meghasharma8855', 'pacmanclicks', 'jaipurshoutout2019', 'ashajain7888', 'himanshu_antil_', 'jyotickashyap', 'aanjulikayadav19', 'drmegb', 'babyaloo2', 'shaurya1007', 'jasmeetkaur_06', 'nazparveen05', 'hackmy_lifestyle', 'nidhigarg9021', 'ratawalpuneet49', 'iriyaajain', 'ocean_designer_collection', 'yourartistry__', 'sangi20', '_.murshi_', 'khatwanideepa01', 'kabirmehra45', 'ila_chaurasia', 'pooja.khare.963', 'tripti0220', 'sushant7595', 'i_am_not_the_name', 'aarti_longani', 'aditi_sirvaiya_', 'awantikasingh', 'malavikabora', 'giftonclick', 'arvindarvind3487', 'aastha.chopra0694', 'nishisingh1516', 'fied.b', 'almaas_talha', 'z.h159', 'rohan_suman', 'ishita.khanna', '_indian_girls_n_boys_shootout_', 'chasing_new_77', 'quote_nation_19', 'shikhar_dhawan_fans_912', 'ankita.srivastava07', 'deka.gautam.13', 'tabishmustufa', 'vanshsarahi', 'syeda9608', 'i_nihung', 'n.nem0o', 'rriddhi', 'gopeshkumar207', 'armansaifi.saifi.568', 'itsmariamalik', 'fa.shion6229', 'amikumar6745', 'subhotourism', 'chaatakdasss', 'simran.chugh', 'priyankachawlamakeovers', 'itrek.in', 'aarsheya_mittal_26', 'ashish___bhalla', 'ankitaaaa_d', '_official_yaar_', 'hasnitgill', 'somyadublish_', 'yashukalfaaz', 'ashish____rana', 'priyatyagi____', 'moumita6541', 'yoshitasharma_14', 'soodingelement', 'aman11sinha', 'leoniweni', 'yogitajhaaa', 'ek.villaine007', 'rosatorovalencia', 'happyhues_sargam', '_priya_003_', '75_akarsh_76', 'ashit_yadav', 'gurpreet_khalsa_222', 'luisangelpimentelrengifo', 'niyati5', 'jorden3966', 'delhipie', 'the_heliophile24', 'javed.ker.4123', 'filmaxzone', 'dineshjat3956', 'rossolaluna', 'officialsubscriptions', 'raj.angela', 'the_back_benchers_7', 'aquib_xargar', '_.knack.__', 'sahilverma29', 'arefarpanahi', 'anurag42084', 'kushushresthaa', 'ravis4647', 'wesal_shilig_', 'shaifali_negi', 'ankitabajpai15', 'rabi.yaaa', 'hie22020', 'miss_amritakaur', 'j.m_19.11', 'h.e.e.m.a.n.e.e_blah_blah', '_saini_99', 'aleemsanaa', 'anshulg343', 'kavya_mohan13', 'blog.20s', 're_vaaaa', 'md_shaaf_shakh', 'rafiqaenan', 'iamshrey___', 'jbstudentlaundryservice', 'harshit.goyal0711', 'annu_abhotosh', 'gshashi863', 'sanya_arora22', 'shooby.shoo', 'finding.muse', 'imfestbouy', 'ashmikabeohar', 'shubham.aryan24', 'craftine1205', 'shreyabatraa', 'my_name_is_billimosi_', 'bbtramboo', 'corporatecaffeine', 'mansi_ohlyan_', 'fashionhub_best', 'leetanshiii', 'ruhanika_love', 'adityamk2', 'spicy.suraj', 'riaaaa.pvtttt', 'nik_varuna', 'living_dead.08', 'bond.over.food', 'jayant___13', 'sanjeevjain6192', 'sutreja', 'pinkyprasad15', 'ria_gulati', '22.91am', 'karthik_ravi', 'kartikey.__.013', 'arthursabino17', 'akshita_sharma_sk', '_nivan_116_', 'angelina_r_ambrose', 'cutezzziyaa', 'sidtiw288', 'being_harshit_thakur', 'alekshendra_the_champ', 'ananya_joshi14', 'sanavyaaaa', 'pankaj_fulera', 'strong_wills', '_anuukritii._', 'desiadda98', 'gauravchaudhary_7000', 'sonalii_2304', '_artistic_soul____', 'rxbyu', 'ishitajasoriya', 'vemohit', 'kartikgupta21', 'rajnisharma_04', 'streetfood5225', 'rajaaurrunk', 'p_thedreamy', 'amiteshkhanna31', 'daddy_diooooo', 'drishtisetia29', 'the_moment_capture_', 'sachi.sri.90', 'narayanansharanya', 'kaura.geous', 'makeupshakeupbyshwetabhutani', 'asha.meena.982', 'macpufff', 'cake_desire_gurgaon', 'drinkshunya', 'himalayan_sikh', 'mayank___lekhwani', 'omshivampateriya', 'shikhav5', 'xmad_over_foodx', 'moremeghana', 'fjdzvv', 'muskaaan1205', 'chandankr0001', 'shamilakohli', 'devidaskulkarni64', 'akshayrana096', 'gavinisharath', 'sorabh07', 'royal888000', 'muskang1612', '_poooja24_', 'harshhchauhan19', 'jatish_ahuja', 'artistry_06', 'anie_saints', 'rimmykainth', 'abhisheks1304', 'x._.vi_mcmxcviii', 'tarveenbd', 'itsfingerlickinfood', 'rajni.rani8', 'khusbu_kejriwal', 'theprateekniku', 'delara_jen', 'umiarova.irina', 'mokshitakamboj', 'adityaasingh1707', 'hitakshi8777', 'ceoopoie', 'doodlekaniya', 'imranali7043', 'parthvee_gor28', 'kritika_devgan', 'veer_to', 'smi.sha', 'g_aasheesh', 'dil_jeet106', 'fatima242794', 'foodies07_']\n"
     ]
    }
   ],
   "source": [
    "# Q6.1-Q6.2\n",
    "## NOTE: If foodtalkindia's followers count is less then run it one more time it will give the correct data\n",
    "## Reason for not getting correct in first time is data tramission over the internet.\n",
    "## Please replace the user_handle to your user_handle for my_followers and i_am_following lists.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Answer: Here I have made one function that takes two arguments. First argument is for\n",
    "what we are looking i.e following or follower, second argument is the user handle for which \n",
    "we want to see. There are four list and each one of them has separate work. \n",
    "The first two store the 500 followers of mentioned user_handles, and other two are\n",
    "for own followers and following user_handles which is helping to decide which follower\n",
    "from the foodtalkindia follower we are following and that follower doesn't follow back.\n",
    "\"\"\"\n",
    "def get_user_ids(is_following,user_handle):\n",
    "    driver.get('https://instagram.com')\n",
    "    search_input = driver.find_element_by_xpath(\"//input[@placeholder='Search']\")\n",
    "    search_input.clear()\n",
    "    search_input.send_keys(user_handle)\n",
    "    time.sleep(3)\n",
    "    user_id = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"fuqBx\"]//a')))\n",
    "    user_id.click()\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        follower_button = driver.find_element_by_partial_link_text(is_following)\n",
    "    except:\n",
    "        return []\n",
    "    time.sleep(2)\n",
    "    follower_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    current_height = 0\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            prev_height = current_height\n",
    "            current_height = driver.execute_script('return document.querySelector(\".isgrP\").scrollHeight;')\n",
    "            driver.execute_script('document.querySelector(\".isgrP\").scrollTo(0,arguments[0]);',current_height)\n",
    "            time.sleep(1)\n",
    "            if prev_height==current_height:\n",
    "                break\n",
    "            i+=5\n",
    "            if i==205:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    time.sleep(2)\n",
    "    user_ids = []\n",
    "    followers = driver.find_elements_by_class_name('d7ByH')\n",
    "\n",
    "\n",
    "    for user_id in followers[:500]:\n",
    "        user_id = BeautifulSoup(user_id.find_element_by_tag_name('a').get_attribute('outerHTML'),'html.parser')\n",
    "        user_ids.append(user_id.a.get('title'))\n",
    "\n",
    "    driver.back()\n",
    "    return user_ids\n",
    "\n",
    "    \n",
    "foodtalkindia_follower_ids = get_user_ids(\"followers\",\"foodtalkindia\")\n",
    "time.sleep(3)\n",
    "sodelhi_follower_ids = get_user_ids(\"followers\",\"sodelhi\")\n",
    "time.sleep(3)\n",
    "my_followers = get_user_ids(\"followers\",\"sample\")\n",
    "time.sleep(3)\n",
    "i_am_following = get_user_ids(\"following\",\"sample\")\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "# 500 followers of foodtalkindia\n",
    "print(foodtalkindia_follower_ids)\n",
    "\n",
    "# 500 followers of foodtalkindia\n",
    "print(sodelhi_follower_ids)\n",
    "\n",
    "\n",
    "# Print follower of foodtalkindia who are being followed by me and they aren't following back\n",
    "for user_id in i_am_following:\n",
    "    if user_id in foodtalkindia_follower_ids and user_id not in my_followers:\n",
    "        print(user_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. CodingNinja Story\n",
    "\"\"\"\n",
    "Answer: Here I have made one function named see_user_story which will return one string out of these three strings \n",
    "1. \"Now seeing stories\"\n",
    "2. \"Already seen stories\"\n",
    "3. \"No story avaiable\" based on the conditions. \n",
    "I have made this function generic so it will work for all the user_handle not only for coding.ninjas. First time if you \n",
    "are checking the user_handle then return 1. Now seeing stories or 2. No story avaiable. If you are checking it for multiple\n",
    "times then it will return any of the three strings. prev_user_handle has been used to check whether we are looking for\n",
    "same user_handle or not. If different then it resets the story_exists, story_seen values. \n",
    "\n",
    "NOTE: Function call will be done in the next cell but you will have to run this cell only once before calling the function\n",
    "in the next cell. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "story_exists = False\n",
    "story_seen = False\n",
    "prev_user_handle = \"\"\n",
    "def see_user_story(user_handle):\n",
    "    global story_exists\n",
    "    global story_seen\n",
    "    global prev_user_handle\n",
    "    if prev_user_handle!=user_handle:\n",
    "        prev_user_handle = user_handle\n",
    "        story_exists = False\n",
    "        story_seen = False\n",
    "        \n",
    "    try:\n",
    "        if story_exists!=True:\n",
    "            driver.get('https://instagram.com')\n",
    "            search_input = driver.find_element_by_xpath(\"//input[@placeholder='Search']\")\n",
    "            search_input.clear()\n",
    "            search_input.send_keys(user_handle)\n",
    "            time.sleep(3)\n",
    "            user_id = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"fuqBx\"]//a')))\n",
    "            user_id.click()\n",
    "            time.sleep(2)\n",
    "            store_present = driver.find_element_by_xpath(\"//div[@class='RR-M- h5uC0']\")\n",
    "            story_exists = True\n",
    "    except:\n",
    "        story_exists = False\n",
    "        \n",
    "    if story_exists:\n",
    "        if story_seen!=True:\n",
    "            store_present.click()\n",
    "            story_seen = True\n",
    "            return \"Now seeing stories\"\n",
    "        else:\n",
    "            return \"Aready seen stories\"\n",
    "    else:\n",
    "        return \"No story available\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aready seen stories\n"
     ]
    }
   ],
   "source": [
    "# Call here\n",
    "status = see_user_story(\"coding.ninjas\")\n",
    "print(status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
